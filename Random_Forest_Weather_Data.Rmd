---
title: "Random Forest Weather Data"
author: "Samantha Bothwell"
date: "6/11/2019"
output: pdf_document
---
The random forest algorithm is a form of supervised learning. Random Forests are a form of decision trees. In the algorithm, trees are built by choosing a random subset of variables and then the model averages the predicitons of all the trees.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

```{r load packages}
# Load important packages
library(tidyr)
library(randomForest)
library(dplyr)
library(party)
library(rpart)
library(rpart.plot)
library(rattle)
library(AUCRF)
library(ggplot2)
library(pdp)
```

```{r clean data}
# First we read in the data and clean it
setwd("/Users/sbothwell/Desktop/DATAS/My_material")
dat = read.csv("Weather.csv", stringsAsFactors = FALSE)

# Remove first column
dat = dat[,-1]

# Rename columns
colnames(dat) = c("DateTime_MST","Temp_degF","Humidity_Pct","DewPt_degF","Wind_mph",
                  "WindDir_degNorth","Gust_mph","GustDir_degNorth","Pressure_Hg",
                  "Solar_WatPerSqM","Percipitation_in")

# Split date and time
dat = dat %>% separate(`DateTime_MST`, c("Date","Time_MST"), " ")

# Split date
dat = dat %>% separate(Date, c("Year","Month","Day"), "-")

# Split time to make numeric
dat = dat %>% separate(`Time_MST`, c("Time", "Minute"), ":")
dat = dat[,-5]
dat$Time = as.numeric(dat$Time)

# Change numeric month to character
dat$Month = as.numeric(dat$Month)
dat$Month = month.abb[dat$Month]

# remove any NA's from the dataset
dat = dat[complete.cases(dat),]

# all varibles must be numeric or factor for RF to work
dat$Year = as.factor(dat$Year)
dat$Month = as.factor(dat$Month)
dat$Day = as.factor(dat$Day)
```

Now that our data is clean, let's walk through using the Random Forest Algorithm.
First we will make data sets for testing and training. These are random samples from our original data. We will use the training data to make the model and the testing data to evaluate how effective our model is at making predictions. For this data, I will make my training data 75% of the original data set and testing data the other 25% of the original data set. 
```{r make data sets}
set.seed(2019) # set seed for reproducible results

## 75% of the sample size
smp_size <- floor(0.75 * nrow(dat))
train_ind <- sample(seq_len(nrow(dat)), size = smp_size)

train <- dat[train_ind, ]
test <- dat[-train_ind, ]
```
For the model we will try to predict the temperature based on the remaining variables
```{r train the model}
# Random Forest algorithm
model = randomForest(`Temp_degF`~., data = train)
```

We can view one of the trees from the Forest
```{r print a tree}
tree = rpart(model, train)
fancyRpartPlot(tree, palettes=c("Reds"))
```


